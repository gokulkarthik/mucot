Traceback (most recent call last):
  File "/home/gokul.kumar/Desktop/multilingual-qa/main.py", line 157, in <module>
    main(args)
  File "/home/gokul.kumar/Desktop/multilingual-qa/main.py", line 93, in main
    trainer = CustomTrainer(
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/trainer.py", line 377, in __init__
    self._move_model_to_device(model, args.device)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/trainer.py", line 535, in _move_model_to_device
    model = model.to(device)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.