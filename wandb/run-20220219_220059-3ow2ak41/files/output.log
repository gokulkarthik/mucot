/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 29821
  Num Epochs = 3
  Instantaneous batch size per device = 4
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 8
  Total optimization steps = 2796
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"







  0%|▏                                                                     | 8/2796 [00:14<1:24:03,  1.81s/it]
  0%|▏                                                                    | 10/2796 [00:17<1:10:32,  1.52s/it]***** Running Evaluation *****
  Num examples = 1693
  Batch size = 4














 96%|███████████████████████████████████████████████████████████████████▉   | 406/424 [00:28<00:01, 13.08it/s]
PyTorch: setting up devices█████████████████████████████████████████████████| 424/424 [00:30<00:00, 12.75it/s]
The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).
***** Running Prediction *****
  Num examples = 1693
  Batch size = 8















    main(args)██████████████████████████████████████████████████████████████| 212/212 [00:32<00:00,  6.98it/s]
  File "/home/gokul.kumar/Desktop/multilingual-qa/main.py", line 104, in main
    trainer.train()
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/trainer.py", line 1440, in train
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/trainer.py", line 1565, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/trainer.py", line 2234, in evaluate
    self.control = self.callback_handler.on_evaluate(self.args, self.state, self.control, output.metrics)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/trainer_callback.py", line 374, in on_evaluate
    return self.call_event("on_evaluate", args, state, control, metrics=metrics)
  File "/home/gokul.kumar/.conda/envs/mlqa/lib/python3.9/site-packages/transformers/trainer_callback.py", line 389, in call_event
    result = getattr(callback, event)(
  File "/home/gokul.kumar/Desktop/multilingual-qa/engine.py", line 57, in on_evaluate
    predictions = postprocess_qa_predictions(self.dataset, self.dataset_tokenized,
  File "/home/gokul.kumar/Desktop/multilingual-qa/datasets_local.py", line 169, in postprocess_qa_predictions
    features_per_example[example_id_to_index[feature["example_id"]]].append(i)
KeyError: 'example_id'